## 2019.12.01
1.读关于搜索引擎的论文，四月份的时候用Redis和Java做了一个简单的搜索引擎，但是只是走流程，它并不实用，最近在整理，过几天单开一个repo实验一下，大体步骤分为四步，
爬虫，处理网页，分析并检索，用户交互。

2.我之前总在想所有数据该怎么获取，目前有一个想法，就是让用户去搜索，搜索的过程中完善索引，这样会有一个特点，使用的人越多，它的检索速度就越快越准确，同时在里边加入排名算法，根据检索次数进行排名，会不会更好。

3.爬虫和处理网页是比较核心的两部分，这里目前打算用RankPage实现页面排名，之前的到达哲学不知道是否还适用于这个场景，关于用户交互，可你的那个要有一个负反馈的过程，慢慢写着看。

4.再记录下，可以加一个搜索词纠正的功能

<br>

## 2019.12.02
1.今天看的论文里边主要讨论的是关于`查询对搜索结果排序服务`的问题，这部分最核心的问题是对**搜索结果排序**，具体的影响因素包括以下几点：

- **关键词的常用程度**，越不常用的词权重越高
- **词频及密度**
- **关键词的位置和形式**，，关键词若出现在比较重要的位置，比如标题标签，黑体,H1，说明页面与关键词越相关
- **关键词的距离**，关键词被切分之后，如果匹配出现的，说明其与搜索词的相关程度越大，当“搜索引擎”在页面上连续完整的出现或者“搜索”和“引擎”出现的时候距离比较近．都被认为与其搜索词相关。
- **链接分析及页面权重**，页面之问的链接和权重关系也影响关键词的相关性，其中最重要的是锚文字：页面越多以搜索词为锚义字的导入链接，说明页面的相关性越强。链接分析还包括了链接源页面本身的丰题 、锚艾字周同的文字等。

<br>

2.点出的查询服务的**关键词处理**也需要注意，分别是：

- **分词处理**
- **根据情况对整合搜索是否需要启动进行判断**
- **找出错别字和拼写中出现的错误**
- **去掉中止词**

<br>

3.论文看完后，进一步处理，具体得出所有实行方案，现在还是学习方法的时候(只是刚了解流程，技术细节以及采用何种算法需要到时候定)

<br>

4.此外，还有搜索引擎的分类，大致是以下几类

- **全文搜索引擎**, 国外具有代表性全文搜索引擎Google和国内著名的有百度，它们都是通过从互联网上收集提取的各个网站的信 息而建立的数据库中，检索与用户查询条件匹配的相关记录，然 后按一定的排列顺序将结果集返回给用户。 
- **目录索引**, 目录索引中最具代表性的是Yahoo雅虎。目录索引在严格上 来讲不算是真正的搜索引擎，仅仅是按目录分类的网站链接列表 而已。用户完全可以不用进行关键词查询，仅靠分类目录也可找 到需要的信息 
- **元搜索引擎** ,中文元搜索引擎中具代表性的有搜星搜索引擎。元搜索引擎在接受用户查询请求时，同时在其他多个引擎上进行搜索，并将结果集返回给用户 (白嫖，哈哈哈哈哈哈)
- **垂真搜索引擎** ,垂直搜索引擎是刚刚兴起的一种搜索引擎。不同于通用的网页搜索引擎，**垂直搜索专注于特定的搜索领域和搜索需求**，在其特定的搜索领域有更好的用户体验。相比通用搜索，垂直搜索需 要的硬件成本低、用户需求特定、查询的方式多样 

<br>

5.**关于文章相关度的计算**

最著名相关度计算是Salton教授提出的`向量空间模型（VSM）`，广泛的应用于搜索引擎检索模块的相关度计算，先记在这里，最后统一整理 

## 2019.12.08
1.打算在考科二之前把之前写的搜索引擎整理出来

2.目前分词器打算先用现成得，回头自己再造


## 2019.12.09
1.计组预计明天就看完数值的机器运算，就是定点加减乘除移位，不过手写的还真是麻烦一点

2.数据结构今天看两章，5，6

## 2019.12.12
1.打算新建一个repo，将之前写的搜索引擎搭建到基于Spring Boot 2.3版本上去，这样有以下几个好处

- 使用Maven管理项目，便于打包部署
- 便于提供对外的接口访问
- 便于扩展



2.关于搜索引擎的展望，目前的想法是

- 移植程序，**爬虫部分**改善爬虫机制和爬取策略
- 分析部分，加分词器(HanlCP或者结巴分词都可)，加处理算法
- 索引器部分，倒排使用Lunce，排名算法之前用的是TF-IDF，处理效果一般，可能会多添加集中算法，综合评价权值

- 用户搜索部分，添加搜索界面

## 2019.12.13
1.[搜索引擎爬虫类型简介](https://www.jianshu.com/p/055e29c8d79b)

## 2019.12.25
1.写在圣诞节
- 16年我记得是表白失败，然后人生失意KFC，晚上看了真爱至上
- 17年科研室加班，然后平平淡淡KFC，然后真爱至上
- 18年在大连陪当时的女朋友恰饭，看电影，女孩子哭起来很可爱
- 19年就是现在，在东南亚DOTA2，还行吧

## 2019.12.26
1.有个思路，在redis中搞一个中止词字典，然后利用HanLP分词，去除文中的中止词

2.种草了，NLP可以看看他的书，书才只卖85块，觉得太值了

3.爬取的时候做动作，进行分词，就不用自己原来那种一段一段解析的方法了，那样做效果太差，分词完成之后，去除中止词(用数的结构)，最后一次加入redis,明天进行改造

## 2019.12.30
1.今天不顺利
2.明天是CPU，据说i笑傲率不高的时候吃糖管用
3.明天争取把数据结构思维笔记过一次

## 2019.12.31
1.HanLP文字分析，数据加载到本地并进行配置，各种测试

2.今天是标准分词，CRF分词，极速分词，N-最短路径分词
